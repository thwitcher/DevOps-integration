
==> Audit <==
|---------|------|----------|----------|---------|----------------------|----------------------|
| Command | Args | Profile  |   User   | Version |      Start Time      |       End Time       |
|---------|------|----------|----------|---------|----------------------|----------------------|
| start   |      | minikube | vboxuser | v1.34.0 | 30 Sep 24 15:29 CEST |                      |
| start   |      | minikube | vboxuser | v1.34.0 | 30 Sep 24 15:46 CEST |                      |
| start   |      | minikube | vboxuser | v1.34.0 | 30 Sep 24 18:16 CEST |                      |
| start   |      | minikube | vboxuser | v1.34.0 | 30 Sep 24 18:57 CEST |                      |
| start   |      | minikube | vboxuser | v1.34.0 | 30 Sep 24 19:00 CEST |                      |
| start   |      | minikube | vboxuser | v1.34.0 | 01 Oct 24 07:14 CEST |                      |
| delete  |      | minikube | vboxuser | v1.34.0 | 01 Oct 24 07:16 CEST | 01 Oct 24 07:17 CEST |
| start   |      | minikube | vboxuser | v1.34.0 | 01 Oct 24 07:17 CEST |                      |
|---------|------|----------|----------|---------|----------------------|----------------------|


==> Last Start <==
Log file created at: 2024/10/01 07:17:22
Running on machine: ubuntu-VM
Binary: Built with gc go1.22.5 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1001 07:17:22.800109    2830 out.go:345] Setting OutFile to fd 1 ...
I1001 07:17:22.800243    2830 out.go:397] isatty.IsTerminal(1) = true
I1001 07:17:22.800246    2830 out.go:358] Setting ErrFile to fd 2...
I1001 07:17:22.800250    2830 out.go:397] isatty.IsTerminal(2) = true
I1001 07:17:22.800371    2830 root.go:338] Updating PATH: /home/vboxuser/.minikube/bin
W1001 07:17:22.800449    2830 root.go:314] Error reading config file at /home/vboxuser/.minikube/config/config.json: open /home/vboxuser/.minikube/config/config.json: no such file or directory
I1001 07:17:22.801796    2830 out.go:352] Setting JSON to false
I1001 07:17:22.803147    2830 start.go:129] hostinfo: {"hostname":"ubuntu-VM","uptime":391,"bootTime":1727759452,"procs":197,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"22.04","kernelVersion":"6.8.0-45-generic","kernelArch":"x86_64","virtualizationSystem":"vbox","virtualizationRole":"guest","hostId":"7ff0007f-5542-4aee-8f26-5e8ec5e94195"}
I1001 07:17:22.803199    2830 start.go:139] virtualization: vbox guest
I1001 07:17:22.804736    2830 out.go:177] ðŸ˜„  minikube v1.34.0 on Ubuntu 22.04 (vbox/amd64)
I1001 07:17:22.807121    2830 driver.go:394] Setting default libvirt URI to qemu:///system
I1001 07:17:22.807139    2830 global.go:112] Querying for installed drivers using PATH=/home/vboxuser/.minikube/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin
I1001 07:17:22.807175    2830 global.go:133] vmware default: false priority: 5, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "vmrun": executable file not found in $PATH Reason: Fix:Install vmrun Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/ Version:}
I1001 07:17:22.807402    2830 notify.go:220] Checking for updates...
I1001 07:17:22.900155    2830 docker.go:123] docker version: linux-27.3.1:Docker Engine - Community
I1001 07:17:22.900243    2830 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1001 07:17:23.340813    2830 info.go:266] docker info: {ID:b2207ff6-5ae5-4464-ba1c-16498730a1c4 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:23 OomKillDisable:false NGoroutines:39 SystemTime:2024-10-01 07:17:23.299779592 +0200 CEST LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.8.0-45-generic OperatingSystem:Ubuntu 22.04.1 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:4371005440 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ubuntu-VM Labels:[] ExperimentalBuild:false ServerVersion:27.3.1 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c Expected:7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c} RuncCommit:{ID:v1.1.14-0-g2c9f560 Expected:v1.1.14-0-g2c9f560} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:[WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.17.1] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.29.7]] Warnings:<nil>}}
I1001 07:17:23.341057    2830 docker.go:318] overlay module found
I1001 07:17:23.341073    2830 global.go:133] docker default: true priority: 9, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1001 07:17:23.357463    2830 global.go:133] none default: false priority: 4, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:running the 'none' driver as a regular user requires sudo permissions Reason: Fix: Doc: Version:}
I1001 07:17:23.357626    2830 global.go:133] podman default: true priority: 7, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "podman": executable file not found in $PATH Reason: Fix:Install Podman Doc:https://minikube.sigs.k8s.io/docs/drivers/podman/ Version:}
I1001 07:17:23.357652    2830 global.go:133] ssh default: false priority: 4, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1001 07:17:23.357717    2830 global.go:133] kvm2 default: true priority: 8, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "virsh": executable file not found in $PATH Reason: Fix:Install libvirt Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/kvm2/ Version:}
I1001 07:17:23.357793    2830 global.go:133] qemu2 default: true priority: 7, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "qemu-system-x86_64": executable file not found in $PATH Reason: Fix:Install qemu-system Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/qemu/ Version:}
I1001 07:17:23.357846    2830 global.go:133] virtualbox default: true priority: 6, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:unable to find VBoxManage in $PATH Reason: Fix:Install VirtualBox Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/virtualbox/ Version:}
I1001 07:17:23.357859    2830 driver.go:316] not recommending "ssh" due to default: false
I1001 07:17:23.357868    2830 driver.go:351] Picked: docker
I1001 07:17:23.357880    2830 driver.go:352] Alternatives: [ssh]
I1001 07:17:23.357884    2830 driver.go:353] Rejects: [vmware none podman kvm2 qemu2 virtualbox]
I1001 07:17:23.360047    2830 out.go:177] âœ¨  Automatically selected the docker driver
I1001 07:17:23.361280    2830 start.go:297] selected driver: docker
I1001 07:17:23.361288    2830 start.go:901] validating driver "docker" against <nil>
I1001 07:17:23.361299    2830 start.go:912] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1001 07:17:23.361375    2830 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1001 07:17:23.490040    2830 info.go:266] docker info: {ID:b2207ff6-5ae5-4464-ba1c-16498730a1c4 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:23 OomKillDisable:false NGoroutines:39 SystemTime:2024-10-01 07:17:23.475895544 +0200 CEST LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.8.0-45-generic OperatingSystem:Ubuntu 22.04.1 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:4371005440 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ubuntu-VM Labels:[] ExperimentalBuild:false ServerVersion:27.3.1 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c Expected:7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c} RuncCommit:{ID:v1.1.14-0-g2c9f560 Expected:v1.1.14-0-g2c9f560} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:[WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.17.1] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.29.7]] Warnings:<nil>}}
I1001 07:17:23.490164    2830 start_flags.go:310] no existing cluster config was found, will generate one from the flags 
I1001 07:17:23.490379    2830 start_flags.go:393] Using suggested 2200MB memory alloc based on sys=4168MB, container=4168MB
I1001 07:17:23.490492    2830 start_flags.go:929] Wait components to verify : map[apiserver:true system_pods:true]
I1001 07:17:23.492102    2830 out.go:177] ðŸ“Œ  Using Docker driver with root privileges
I1001 07:17:23.493302    2830 cni.go:84] Creating CNI manager for ""
I1001 07:17:23.493317    2830 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1001 07:17:23.493324    2830 start_flags.go:319] Found "bridge CNI" CNI - setting NetworkPlugin=cni
I1001 07:17:23.493375    2830 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/vboxuser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I1001 07:17:23.494807    2830 out.go:177] ðŸ‘  Starting "minikube" primary control-plane node in "minikube" cluster
I1001 07:17:23.495797    2830 cache.go:121] Beginning downloading kic base image for docker with docker
I1001 07:17:23.496657    2830 out.go:177] ðŸšœ  Pulling base image v0.0.45 ...
I1001 07:17:23.497705    2830 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I1001 07:17:23.497763    2830 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local docker daemon
W1001 07:17:23.532518    2830 image.go:95] image gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 is of wrong architecture
I1001 07:17:23.532526    2830 cache.go:149] Downloading gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 to local cache
I1001 07:17:23.532668    2830 image.go:63] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory
I1001 07:17:23.533439    2830 image.go:66] Found gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory, skipping pull
I1001 07:17:23.533455    2830 image.go:135] gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 exists in cache, skipping pull
I1001 07:17:23.533464    2830 cache.go:152] successfully saved gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 as a tarball
I1001 07:17:23.533468    2830 cache.go:162] Loading gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 from local cache
I1001 07:17:23.534207    2830 cache.go:168] failed to download gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85, will try fallback image if available: tarball: unexpected EOF
I1001 07:17:23.534216    2830 image.go:79] Checking for docker.io/kicbase/stable:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local docker daemon
I1001 07:17:23.560529    2830 cache.go:149] Downloading docker.io/kicbase/stable:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 to local cache
I1001 07:17:23.560759    2830 image.go:63] Checking for docker.io/kicbase/stable:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory
I1001 07:17:23.560784    2830 image.go:148] Writing docker.io/kicbase/stable:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 to local cache
I1001 07:17:24.841484    2830 preload.go:118] Found remote preload: https://storage.googleapis.com/minikube-preloaded-volume-tarballs/v18/v1.31.0/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4
I1001 07:17:24.841505    2830 cache.go:56] Caching tarball of preloaded images
I1001 07:17:24.841678    2830 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I1001 07:17:24.848839    2830 out.go:177] ðŸ’¾  Downloading Kubernetes v1.31.0 preload ...
I1001 07:17:24.851431    2830 preload.go:236] getting checksum for preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4 ...
I1001 07:17:26.692464    2830 download.go:107] Downloading: https://storage.googleapis.com/minikube-preloaded-volume-tarballs/v18/v1.31.0/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4?checksum=md5:2dd98f97b896d7a4f012ee403b477cc8 -> /home/vboxuser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4
I1001 07:25:24.943368    2830 cache.go:168] failed to download docker.io/kicbase/stable:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85, will try fallback image if available: writing tarball image: read tcp 10.0.2.15:40072->104.16.101.215:443: read: connection reset by peer
I1001 07:25:24.943411    2830 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45 in local docker daemon
W1001 07:25:24.966517    2830 image.go:95] image gcr.io/k8s-minikube/kicbase:v0.0.45 is of wrong architecture
I1001 07:25:24.966530    2830 cache.go:149] Downloading gcr.io/k8s-minikube/kicbase:v0.0.45 to local cache
I1001 07:25:24.966728    2830 image.go:63] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45 in local cache directory
I1001 07:25:24.966778    2830 image.go:148] Writing gcr.io/k8s-minikube/kicbase:v0.0.45 to local cache
W1001 07:25:27.355274    2830 cache.go:62] Error downloading preloaded artifacts will continue without preload: download failed: https://storage.googleapis.com/minikube-preloaded-volume-tarballs/v18/v1.31.0/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4?checksum=md5:2dd98f97b896d7a4f012ee403b477cc8: getter: &{Ctx:context.Background Src:https://storage.googleapis.com/minikube-preloaded-volume-tarballs/v18/v1.31.0/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4?checksum=md5:2dd98f97b896d7a4f012ee403b477cc8 Dst:/home/vboxuser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4.download Pwd: Mode:2 Umask:---------- Detectors:[0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820] Decompressors:map[bz2:0xc0000e2d60 gz:0xc0000e2d68 tar:0xc0000e2cf0 tar.bz2:0xc0000e2d10 tar.gz:0xc0000e2d20 tar.xz:0xc0000e2d40 tar.zst:0xc0000e2d50 tbz2:0xc0000e2d10 tgz:0xc0000e2d20 txz:0xc0000e2d40 tzst:0xc0000e2d50 xz:0xc0000e2d70 zip:0xc0000e2d80 zst:0xc0000e2d78] Getters:map[file:0xc0013bd510 http:0xc001858a00 https:0xc001858a50] Dir:false ProgressListener:0x4e44750 Insecure:false DisableSymlinks:false Options:[0x12e5e60]}: read tcp 10.0.2.15:40098->216.58.204.251:443: read: connection reset by peer
I1001 07:25:27.355607    2830 profile.go:143] Saving config to /home/vboxuser/.minikube/profiles/minikube/config.json ...
I1001 07:25:27.355636    2830 lock.go:35] WriteFile acquiring /home/vboxuser/.minikube/profiles/minikube/config.json: {Name:mkbb6432aadb9fa9017682bb5512221a940d0308 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1001 07:25:27.355845    2830 cache.go:107] acquiring lock: {Name:mk0d81ea496b45383c03e93d2c091a525956e1e0 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.356183    2830 cache.go:107] acquiring lock: {Name:mk87bd41ddb99adcee6fbdec0674b16f28bab55a Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.356577    2830 cache.go:107] acquiring lock: {Name:mk8eef87bf7a81ff5bc56c2ffb7502566db2a579 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.356714    2830 cache.go:107] acquiring lock: {Name:mke6a96d1260766c14793c12d3b0f6ab75176bd5 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.356994    2830 cache.go:107] acquiring lock: {Name:mk15f0b49304394af1dbcc28e9e52d917b864e82 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.357482    2830 image.go:135] retrieving image: registry.k8s.io/pause:3.10
I1001 07:25:27.357637    2830 cache.go:107] acquiring lock: {Name:mk6a5ca1f0b155de4bd506a7d0b7b757179fdcc6 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.358118    2830 image.go:135] retrieving image: registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:25:27.358274    2830 image.go:135] retrieving image: registry.k8s.io/kube-proxy:v1.31.0
I1001 07:25:27.358348    2830 image.go:135] retrieving image: registry.k8s.io/etcd:3.5.15-0
I1001 07:25:27.358445    2830 image.go:135] retrieving image: gcr.io/k8s-minikube/storage-provisioner:v5
I1001 07:25:27.358495    2830 image.go:135] retrieving image: registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:25:27.358648    2830 cache.go:107] acquiring lock: {Name:mk76376a420e4a9214c33a50ea53750cd713e255 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.358730    2830 image.go:135] retrieving image: registry.k8s.io/kube-scheduler:v1.31.0
I1001 07:25:27.357872    2830 cache.go:107] acquiring lock: {Name:mk3bd16d51ad9ce8cb9c9b74b150deaca15a7101 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:25:27.359667    2830 image.go:135] retrieving image: registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:25:27.360151    2830 image.go:178] daemon lookup for registry.k8s.io/kube-proxy:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-proxy:v1.31.0
I1001 07:25:27.360539    2830 image.go:178] daemon lookup for registry.k8s.io/kube-apiserver:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:25:27.360623    2830 image.go:178] daemon lookup for registry.k8s.io/coredns/coredns:v1.11.1: Error response from daemon: No such image: registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:25:27.360734    2830 image.go:178] daemon lookup for gcr.io/k8s-minikube/storage-provisioner:v5: Error response from daemon: No such image: gcr.io/k8s-minikube/storage-provisioner:v5
I1001 07:25:27.360762    2830 image.go:178] daemon lookup for registry.k8s.io/kube-controller-manager:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:25:27.360846    2830 image.go:178] daemon lookup for registry.k8s.io/etcd:3.5.15-0: Error response from daemon: No such image: registry.k8s.io/etcd:3.5.15-0
I1001 07:25:27.361718    2830 image.go:178] daemon lookup for registry.k8s.io/pause:3.10: Error response from daemon: No such image: registry.k8s.io/pause:3.10
I1001 07:25:27.361800    2830 image.go:178] daemon lookup for registry.k8s.io/kube-scheduler:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-scheduler:v1.31.0
W1001 07:25:55.446806    2830 image.go:188] authn lookup for gcr.io/k8s-minikube/storage-provisioner:v5 (trying anon): Get "https://gcr.io/v2/": dial tcp: lookup gcr.io on 127.0.0.53:53: read udp 127.0.0.1:51228->127.0.0.53:53: i/o timeout
I1001 07:25:55.446873    2830 cache.go:168] failed to download gcr.io/k8s-minikube/kicbase:v0.0.45, will try fallback image if available: getting remote image: Get "https://gcr.io/v2/": dial tcp: lookup gcr.io on 127.0.0.53:53: read udp 127.0.0.1:51228->127.0.0.53:53: i/o timeout
I1001 07:25:55.446890    2830 image.go:79] Checking for docker.io/kicbase/stable:v0.0.45 in local docker daemon
I1001 07:25:55.466767    2830 cache.go:149] Downloading docker.io/kicbase/stable:v0.0.45 to local cache
I1001 07:25:55.466929    2830 image.go:63] Checking for docker.io/kicbase/stable:v0.0.45 in local cache directory
I1001 07:25:55.466950    2830 image.go:148] Writing docker.io/kicbase/stable:v0.0.45 to local cache
W1001 07:25:57.869954    2830 image.go:188] authn lookup for registry.k8s.io/coredns/coredns:v1.11.1 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
W1001 07:25:57.870144    2830 image.go:188] authn lookup for registry.k8s.io/kube-proxy:v1.31.0 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
W1001 07:25:57.870210    2830 image.go:188] authn lookup for registry.k8s.io/pause:3.10 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
W1001 07:25:57.870244    2830 image.go:188] authn lookup for registry.k8s.io/kube-controller-manager:v1.31.0 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
W1001 07:25:57.870252    2830 image.go:188] authn lookup for registry.k8s.io/etcd:3.5.15-0 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
W1001 07:25:57.870279    2830 image.go:188] authn lookup for registry.k8s.io/kube-apiserver:v1.31.0 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
W1001 07:25:57.870310    2830 image.go:188] authn lookup for registry.k8s.io/kube-scheduler:v1.31.0 (trying anon): Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:38055->127.0.0.53:53: i/o timeout
I1001 07:26:25.987263    2830 image.go:192] remote lookup for gcr.io/k8s-minikube/storage-provisioner:v5: Get "https://gcr.io/v2/": dial tcp: lookup gcr.io on 127.0.0.53:53: read udp 127.0.0.1:57517->127.0.0.53:53: i/o timeout
I1001 07:26:25.987295    2830 cache.go:96] cache image "gcr.io/k8s-minikube/storage-provisioner:v5" -> "/home/vboxuser/.minikube/cache/images/amd64/gcr.io/k8s-minikube/storage-provisioner_v5" took 58.631452865s
W1001 07:26:25.987362    2830 out.go:270] â—  The image 'gcr.io/k8s-minikube/storage-provisioner:v5' was not found; unable to add it to cache.
I1001 07:26:26.081702    2830 cache.go:168] failed to download docker.io/kicbase/stable:v0.0.45, will try fallback image if available: getting remote image: Get "https://index.docker.io/v2/": dial tcp: lookup index.docker.io on 127.0.0.53:53: read udp 127.0.0.1:33163->127.0.0.53:53: i/o timeout
E1001 07:26:26.081723    2830 cache.go:189] Error downloading kic artifacts:  failed to download kic base image or any fallback image
I1001 07:26:26.081768    2830 cache.go:194] Successfully downloaded all kic artifacts
I1001 07:26:26.081793    2830 start.go:360] acquireMachinesLock for minikube: {Name:mk0d0e852e27deacae7c71a770cf19d38e9b2390 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1001 07:26:26.081915    2830 start.go:364] duration metric: took 106.87Âµs to acquireMachinesLock for "minikube"
I1001 07:26:26.081931    2830 start.go:93] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/vboxuser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} &{Name: IP: Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I1001 07:26:26.081996    2830 start.go:125] createHost starting for "" (driver="docker")
I1001 07:26:26.085877    2830 out.go:235] ðŸ”¥  Creating docker container (CPUs=2, Memory=2200MB) ...
I1001 07:26:26.086285    2830 start.go:159] libmachine.API.Create for "minikube" (driver="docker")
I1001 07:26:26.086307    2830 client.go:168] LocalClient.Create starting
I1001 07:26:26.086736    2830 main.go:141] libmachine: Creating CA: /home/vboxuser/.minikube/certs/ca.pem
I1001 07:26:26.166343    2830 main.go:141] libmachine: Creating client certificate: /home/vboxuser/.minikube/certs/cert.pem
I1001 07:26:26.354798    2830 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W1001 07:26:26.373260    2830 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I1001 07:26:26.373341    2830 network_create.go:284] running [docker network inspect minikube] to gather additional debugging logs...
I1001 07:26:26.373353    2830 cli_runner.go:164] Run: docker network inspect minikube
W1001 07:26:26.388665    2830 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I1001 07:26:26.388683    2830 network_create.go:287] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error response from daemon: network minikube not found
I1001 07:26:26.388691    2830 network_create.go:289] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error response from daemon: network minikube not found

** /stderr **
I1001 07:26:26.388768    2830 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I1001 07:26:26.404727    2830 network.go:206] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 IsPrivate:true Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:} reservation:0xc0000e39c0}
I1001 07:26:26.404747    2830 network_create.go:124] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 1500 ...
I1001 07:26:26.404781    2830 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I1001 07:26:26.528207    2830 network_create.go:108] docker network minikube 192.168.49.0/24 created
I1001 07:26:26.528225    2830 kic.go:121] calculated static IP "192.168.49.2" for the "minikube" container
I1001 07:26:26.528273    2830 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I1001 07:26:26.550552    2830 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I1001 07:26:26.566617    2830 oci.go:103] Successfully created a docker volume minikube
I1001 07:26:26.566669    2830 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 -d /var/lib
I1001 07:26:27.521517    2830 oci.go:107] Successfully prepared a docker volume minikube
I1001 07:26:27.521532    2830 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I1001 07:26:27.521548    2830 kic.go:194] Starting extracting preloaded images to volume ...
I1001 07:26:27.521616    2830 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v /home/vboxuser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 -I lz4 -xf /preloaded.tar -C /extractDir
W1001 07:26:27.894873    2830 cli_runner.go:211] docker run --rm --entrypoint /usr/bin/tar -v /home/vboxuser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 -I lz4 -xf /preloaded.tar -C /extractDir returned with exit code 2
I1001 07:26:27.894927    2830 kic.go:201] Unable to extract preloaded tarball to volume: docker run --rm --entrypoint /usr/bin/tar -v /home/vboxuser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 -I lz4 -xf /preloaded.tar -C /extractDir: exit status 2
stdout:

stderr:
tar (child): /preloaded.tar: Cannot read: Is a directory
tar (child): At beginning of tape, quitting now
tar (child): Error is not recoverable: exiting now
/usr/bin/tar: Child returned status 2
/usr/bin/tar: Error is not recoverable: exiting now
W1001 07:26:27.895049    2830 cgroups_linux.go:77] Your kernel does not support swap limit capabilities or the cgroup is not mounted.
W1001 07:26:27.895073    2830 oci.go:243] Your kernel does not support CPU cfs period/quota or the cgroup is not mounted.
I1001 07:26:27.895100    2830 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I1001 07:26:27.941056    2830 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85
I1001 07:26:28.296848    2830 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I1001 07:26:28.327304    2830 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1001 07:26:28.354034    2830 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I1001 07:26:28.371294    2830 image.go:192] remote lookup for registry.k8s.io/kube-apiserver:v1.31.0: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.371323    2830 cache.go:96] cache image "registry.k8s.io/kube-apiserver:v1.31.0" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-apiserver_v1.31.0" took 1m1.014627084s
W1001 07:26:28.371363    2830 out.go:270] â—  The image 'registry.k8s.io/kube-apiserver:v1.31.0' was not found; unable to add it to cache.
I1001 07:26:28.371547    2830 image.go:192] remote lookup for registry.k8s.io/kube-scheduler:v1.31.0: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.371562    2830 cache.go:96] cache image "registry.k8s.io/kube-scheduler:v1.31.0" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-scheduler_v1.31.0" took 1m1.012919254s
W1001 07:26:28.371588    2830 out.go:270] â—  The image 'registry.k8s.io/kube-scheduler:v1.31.0' was not found; unable to add it to cache.
I1001 07:26:28.371972    2830 image.go:192] remote lookup for registry.k8s.io/kube-controller-manager:v1.31.0: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.371988    2830 cache.go:96] cache image "registry.k8s.io/kube-controller-manager:v1.31.0" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-controller-manager_v1.31.0" took 1m1.014122699s
W1001 07:26:28.372011    2830 out.go:270] â—  The image 'registry.k8s.io/kube-controller-manager:v1.31.0' was not found; unable to add it to cache.
I1001 07:26:28.372963    2830 image.go:192] remote lookup for registry.k8s.io/kube-proxy:v1.31.0: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.372988    2830 cache.go:96] cache image "registry.k8s.io/kube-proxy:v1.31.0" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-proxy_v1.31.0" took 1m1.016839145s
W1001 07:26:28.373025    2830 out.go:270] â—  The image 'registry.k8s.io/kube-proxy:v1.31.0' was not found; unable to add it to cache.
I1001 07:26:28.373099    2830 image.go:192] remote lookup for registry.k8s.io/pause:3.10: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.373171    2830 cache.go:96] cache image "registry.k8s.io/pause:3.10" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/pause_3.10" took 1m1.016621597s
W1001 07:26:28.373199    2830 out.go:270] â—  The image 'registry.k8s.io/pause:3.10' was not found; unable to add it to cache.
I1001 07:26:28.373695    2830 image.go:192] remote lookup for registry.k8s.io/etcd:3.5.15-0: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.373716    2830 cache.go:96] cache image "registry.k8s.io/etcd:3.5.15-0" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/etcd_3.5.15-0" took 1m1.016726831s
W1001 07:26:28.373771    2830 out.go:270] â—  The image 'registry.k8s.io/etcd:3.5.15-0' was not found; unable to add it to cache.
I1001 07:26:28.373574    2830 image.go:192] remote lookup for registry.k8s.io/coredns/coredns:v1.11.1: Get "https://registry.k8s.io/v2/": dial tcp: lookup registry.k8s.io on 127.0.0.53:53: read udp 127.0.0.1:55240->127.0.0.53:53: i/o timeout
I1001 07:26:28.374147    2830 cache.go:96] cache image "registry.k8s.io/coredns/coredns:v1.11.1" -> "/home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/coredns/coredns_v1.11.1" took 1m1.016485443s
W1001 07:26:28.374588    2830 out.go:270] â—  The image 'registry.k8s.io/coredns/coredns:v1.11.1' was not found; unable to add it to cache.
I1001 07:26:28.375289    2830 cache.go:87] Successfully saved all images to host disk.
I1001 07:26:28.453225    2830 oci.go:144] the created container "minikube" has a running status.
I1001 07:26:28.453251    2830 kic.go:225] Creating ssh key for kic: /home/vboxuser/.minikube/machines/minikube/id_rsa...
I1001 07:26:28.591041    2830 kic_runner.go:191] docker (temp): /home/vboxuser/.minikube/machines/minikube/id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I1001 07:26:28.613303    2830 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1001 07:26:28.628867    2830 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I1001 07:26:28.628876    2830 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I1001 07:26:28.682911    2830 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1001 07:26:28.699888    2830 machine.go:93] provisionDockerMachine start ...
I1001 07:26:28.699994    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:28.715789    2830 main.go:141] libmachine: Using SSH client type: native
I1001 07:26:28.715944    2830 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I1001 07:26:28.715949    2830 main.go:141] libmachine: About to run SSH command:
hostname
I1001 07:26:28.716580    2830 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:53874->127.0.0.1:32768: read: connection reset by peer
I1001 07:26:31.717884    2830 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:53886->127.0.0.1:32768: read: connection reset by peer
I1001 07:26:34.866013    2830 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1001 07:26:34.866026    2830 ubuntu.go:169] provisioning hostname "minikube"
I1001 07:26:34.866081    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:34.884764    2830 main.go:141] libmachine: Using SSH client type: native
I1001 07:26:34.884908    2830 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I1001 07:26:34.884914    2830 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I1001 07:26:35.099088    2830 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1001 07:26:35.099133    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:35.116662    2830 main.go:141] libmachine: Using SSH client type: native
I1001 07:26:35.116845    2830 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I1001 07:26:35.116854    2830 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I1001 07:26:35.291342    2830 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1001 07:26:35.291388    2830 ubuntu.go:175] set auth options {CertDir:/home/vboxuser/.minikube CaCertPath:/home/vboxuser/.minikube/certs/ca.pem CaPrivateKeyPath:/home/vboxuser/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/vboxuser/.minikube/machines/server.pem ServerKeyPath:/home/vboxuser/.minikube/machines/server-key.pem ClientKeyPath:/home/vboxuser/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/vboxuser/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/vboxuser/.minikube}
I1001 07:26:35.291440    2830 ubuntu.go:177] setting up certificates
I1001 07:26:35.291461    2830 provision.go:84] configureAuth start
I1001 07:26:35.291662    2830 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1001 07:26:35.311105    2830 provision.go:143] copyHostCerts
I1001 07:26:35.311172    2830 exec_runner.go:151] cp: /home/vboxuser/.minikube/certs/key.pem --> /home/vboxuser/.minikube/key.pem (1679 bytes)
I1001 07:26:35.311262    2830 exec_runner.go:151] cp: /home/vboxuser/.minikube/certs/ca.pem --> /home/vboxuser/.minikube/ca.pem (1082 bytes)
I1001 07:26:35.311338    2830 exec_runner.go:151] cp: /home/vboxuser/.minikube/certs/cert.pem --> /home/vboxuser/.minikube/cert.pem (1127 bytes)
I1001 07:26:35.311376    2830 provision.go:117] generating server cert: /home/vboxuser/.minikube/machines/server.pem ca-key=/home/vboxuser/.minikube/certs/ca.pem private-key=/home/vboxuser/.minikube/certs/ca-key.pem org=vboxuser.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I1001 07:26:35.572235    2830 provision.go:177] copyRemoteCerts
I1001 07:26:35.572283    2830 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I1001 07:26:35.572311    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:35.589345    2830 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/vboxuser/.minikube/machines/minikube/id_rsa Username:docker}
I1001 07:26:35.723369    2830 ssh_runner.go:362] scp /home/vboxuser/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I1001 07:26:35.758098    2830 ssh_runner.go:362] scp /home/vboxuser/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I1001 07:26:35.783389    2830 ssh_runner.go:362] scp /home/vboxuser/.minikube/machines/server.pem --> /etc/docker/server.pem (1184 bytes)
I1001 07:26:35.816320    2830 provision.go:87] duration metric: took 524.849362ms to configureAuth
I1001 07:26:35.816333    2830 ubuntu.go:193] setting minikube options for container-runtime
I1001 07:26:35.816449    2830 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I1001 07:26:35.816486    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:35.833907    2830 main.go:141] libmachine: Using SSH client type: native
I1001 07:26:35.834037    2830 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I1001 07:26:35.834042    2830 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I1001 07:26:36.078814    2830 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I1001 07:26:36.078824    2830 ubuntu.go:71] root file system type: overlay
I1001 07:26:36.078910    2830 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I1001 07:26:36.078957    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:36.096240    2830 main.go:141] libmachine: Using SSH client type: native
I1001 07:26:36.096374    2830 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I1001 07:26:36.096423    2830 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I1001 07:26:36.320643    2830 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I1001 07:26:36.320730    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:36.357670    2830 main.go:141] libmachine: Using SSH client type: native
I1001 07:26:36.357866    2830 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I1001 07:26:36.357877    2830 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I1001 07:26:37.396331    2830 main.go:141] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2024-08-27 14:13:43.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2024-10-01 05:26:36.316365064 +0000
@@ -1,46 +1,49 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service time-set.target
-Wants=network-online.target containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
+Wants=network-online.target
 Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutStartSec=0
-RestartSec=2
-Restart=always
+Restart=on-failure
 
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
+LimitNOFILE=infinity
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I1001 07:26:37.396353    2830 machine.go:96] duration metric: took 8.696453187s to provisionDockerMachine
I1001 07:26:37.396360    2830 client.go:171] duration metric: took 11.310049409s to LocalClient.Create
I1001 07:26:37.396388    2830 start.go:167] duration metric: took 11.310086963s to libmachine.API.Create "minikube"
I1001 07:26:37.396422    2830 start.go:293] postStartSetup for "minikube" (driver="docker")
I1001 07:26:37.396448    2830 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I1001 07:26:37.396534    2830 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I1001 07:26:37.396571    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:37.414822    2830 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/vboxuser/.minikube/machines/minikube/id_rsa Username:docker}
I1001 07:26:37.535919    2830 ssh_runner.go:195] Run: cat /etc/os-release
I1001 07:26:37.541753    2830 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I1001 07:26:37.541770    2830 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I1001 07:26:37.541778    2830 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I1001 07:26:37.541782    2830 info.go:137] Remote host: Ubuntu 22.04.4 LTS
I1001 07:26:37.541791    2830 filesync.go:126] Scanning /home/vboxuser/.minikube/addons for local assets ...
I1001 07:26:37.542326    2830 filesync.go:126] Scanning /home/vboxuser/.minikube/files for local assets ...
I1001 07:26:37.542737    2830 start.go:296] duration metric: took 146.30592ms for postStartSetup
I1001 07:26:37.543050    2830 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1001 07:26:37.560579    2830 profile.go:143] Saving config to /home/vboxuser/.minikube/profiles/minikube/config.json ...
I1001 07:26:37.561142    2830 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I1001 07:26:37.561169    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:37.576727    2830 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/vboxuser/.minikube/machines/minikube/id_rsa Username:docker}
I1001 07:26:37.703976    2830 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I1001 07:26:37.709509    2830 start.go:128] duration metric: took 11.627500057s to createHost
I1001 07:26:37.709523    2830 start.go:83] releasing machines lock for "minikube", held for 11.627602642s
I1001 07:26:37.709638    2830 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1001 07:26:37.727254    2830 ssh_runner.go:195] Run: cat /version.json
I1001 07:26:37.727287    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:37.727485    2830 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I1001 07:26:37.727521    2830 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1001 07:26:37.753502    2830 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/vboxuser/.minikube/machines/minikube/id_rsa Username:docker}
I1001 07:26:37.757084    2830 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/vboxuser/.minikube/machines/minikube/id_rsa Username:docker}
I1001 07:26:53.916132    2830 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (16.188629981s)
I1001 07:26:53.916132    2830 ssh_runner.go:235] Completed: cat /version.json: (16.18886314s)
W1001 07:26:53.916179    2830 start.go:867] [curl -sS -m 2 https://registry.k8s.io/] failed: curl -sS -m 2 https://registry.k8s.io/: Process exited with status 28
stdout:

stderr:
curl: (28) Resolving timed out after 2002 milliseconds
I1001 07:26:53.916303    2830 ssh_runner.go:195] Run: systemctl --version
I1001 07:26:53.928050    2830 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I1001 07:26:53.934092    2830 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I1001 07:26:53.971725    2830 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I1001 07:26:53.971793    2830 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I1001 07:26:54.001417    2830 cni.go:262] disabled [/etc/cni/net.d/87-podman-bridge.conflist, /etc/cni/net.d/100-crio-bridge.conf] bridge cni config(s)
I1001 07:26:54.001429    2830 start.go:495] detecting cgroup driver to use...
I1001 07:26:54.001452    2830 detect.go:190] detected "systemd" cgroup driver on host os
I1001 07:26:54.001604    2830 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I1001 07:26:54.020927    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
I1001 07:26:54.033372    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I1001 07:26:54.044174    2830 containerd.go:146] configuring containerd to use "systemd" as cgroup driver...
I1001 07:26:54.044214    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I1001 07:26:54.061997    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1001 07:26:54.080392    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I1001 07:26:54.091763    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1001 07:26:54.113330    2830 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I1001 07:26:54.134996    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I1001 07:26:54.149065    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I1001 07:26:54.160122    2830 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I1001 07:26:54.171408    2830 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I1001 07:26:54.181756    2830 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I1001 07:26:54.191175    2830 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1001 07:26:54.291159    2830 ssh_runner.go:195] Run: sudo systemctl restart containerd
I1001 07:26:54.430136    2830 start.go:495] detecting cgroup driver to use...
I1001 07:26:54.430165    2830 detect.go:190] detected "systemd" cgroup driver on host os
I1001 07:26:54.430202    2830 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I1001 07:26:54.464573    2830 cruntime.go:279] skipping containerd shutdown because we are bound to it
I1001 07:26:54.464616    2830 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I1001 07:26:54.506390    2830 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I1001 07:26:54.533585    2830 ssh_runner.go:195] Run: which cri-dockerd
I1001 07:26:54.538195    2830 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I1001 07:26:54.559797    2830 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I1001 07:26:54.585777    2830 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I1001 07:26:54.738456    2830 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I1001 07:26:54.856189    2830 docker.go:574] configuring docker to use "systemd" as cgroup driver...
I1001 07:26:54.856293    2830 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I1001 07:26:54.905941    2830 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1001 07:26:55.061775    2830 ssh_runner.go:195] Run: sudo systemctl restart docker
I1001 07:26:55.617084    2830 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I1001 07:26:55.643237    2830 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I1001 07:26:55.663397    2830 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I1001 07:26:55.775329    2830 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1001 07:26:55.876926    2830 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1001 07:26:55.975854    2830 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I1001 07:26:55.996903    2830 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I1001 07:26:56.009771    2830 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1001 07:26:56.106360    2830 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I1001 07:26:56.340288    2830 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I1001 07:26:56.340370    2830 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I1001 07:26:56.345133    2830 start.go:563] Will wait 60s for crictl version
I1001 07:26:56.345170    2830 ssh_runner.go:195] Run: which crictl
I1001 07:26:56.350399    2830 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I1001 07:26:56.487827    2830 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  27.2.0
RuntimeApiVersion:  v1
I1001 07:26:56.487866    2830 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1001 07:26:56.588223    2830 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1001 07:26:56.622849    2830 out.go:235] ðŸ³  Preparing Kubernetes v1.31.0 on Docker 27.2.0 ...
I1001 07:26:56.622985    2830 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I1001 07:26:56.646313    2830 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I1001 07:26:56.656234    2830 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.49.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1001 07:26:56.683940    2830 kubeadm.go:883] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/vboxuser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I1001 07:26:56.684049    2830 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I1001 07:26:56.684100    2830 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1001 07:26:56.718801    2830 docker.go:685] Got preloaded images: 
I1001 07:26:56.718812    2830 docker.go:691] registry.k8s.io/kube-apiserver:v1.31.0 wasn't preloaded
I1001 07:26:56.718850    2830 ssh_runner.go:195] Run: sudo cat /var/lib/docker/image/overlay2/repositories.json
I1001 07:26:56.731882    2830 ssh_runner.go:195] Run: which lz4
I1001 07:26:56.737244    2830 ssh_runner.go:195] Run: stat -c "%s %y" /preloaded.tar.lz4
I1001 07:26:56.742309    2830 ssh_runner.go:352] existence check for /preloaded.tar.lz4: stat -c "%s %y" /preloaded.tar.lz4: Process exited with status 1
stdout:

stderr:
stat: cannot statx '/preloaded.tar.lz4': No such file or directory
I1001 07:26:56.742326    2830 ssh_runner.go:362] scp /home/vboxuser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4 --> /preloaded.tar.lz4 (4096 bytes)
I1001 07:26:56.779886    2830 kubeadm.go:909] preload failed, will try to load cached images: copying file: sudo mkdir -p / && sudo scp -t / && sudo touch -d "2024-10-01 07:26:27.612180659 +0200" /preloaded.tar.lz4: Process exited with status 1
output:   scp: Broken pipe
I1001 07:26:56.779954    2830 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1001 07:26:56.803401    2830 docker.go:685] Got preloaded images: 
I1001 07:26:56.803410    2830 docker.go:691] registry.k8s.io/kube-apiserver:v1.31.0 wasn't preloaded
I1001 07:26:56.803415    2830 cache_images.go:88] LoadCachedImages start: [registry.k8s.io/kube-apiserver:v1.31.0 registry.k8s.io/kube-controller-manager:v1.31.0 registry.k8s.io/kube-scheduler:v1.31.0 registry.k8s.io/kube-proxy:v1.31.0 registry.k8s.io/pause:3.10 registry.k8s.io/etcd:3.5.15-0 registry.k8s.io/coredns/coredns:v1.11.1 gcr.io/k8s-minikube/storage-provisioner:v5]
I1001 07:26:56.804726    2830 image.go:135] retrieving image: gcr.io/k8s-minikube/storage-provisioner:v5
I1001 07:26:56.807218    2830 image.go:135] retrieving image: registry.k8s.io/kube-proxy:v1.31.0
I1001 07:26:56.807618    2830 image.go:135] retrieving image: registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:26:56.808563    2830 image.go:178] daemon lookup for gcr.io/k8s-minikube/storage-provisioner:v5: Error response from daemon: No such image: gcr.io/k8s-minikube/storage-provisioner:v5
I1001 07:26:56.809026    2830 image.go:178] daemon lookup for registry.k8s.io/kube-apiserver:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:26:56.818315    2830 image.go:178] daemon lookup for registry.k8s.io/kube-proxy:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-proxy:v1.31.0
I1001 07:26:56.818357    2830 image.go:135] retrieving image: registry.k8s.io/kube-scheduler:v1.31.0
I1001 07:26:56.818476    2830 image.go:135] retrieving image: registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:26:56.818932    2830 image.go:135] retrieving image: registry.k8s.io/etcd:3.5.15-0
I1001 07:26:56.819114    2830 image.go:135] retrieving image: registry.k8s.io/pause:3.10
I1001 07:26:56.819227    2830 image.go:178] daemon lookup for registry.k8s.io/kube-controller-manager:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:26:56.819331    2830 image.go:135] retrieving image: registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:26:56.820028    2830 image.go:178] daemon lookup for registry.k8s.io/kube-scheduler:v1.31.0: Error response from daemon: No such image: registry.k8s.io/kube-scheduler:v1.31.0
I1001 07:26:56.820265    2830 image.go:178] daemon lookup for registry.k8s.io/pause:3.10: Error response from daemon: No such image: registry.k8s.io/pause:3.10
I1001 07:26:56.820217    2830 image.go:178] daemon lookup for registry.k8s.io/etcd:3.5.15-0: Error response from daemon: No such image: registry.k8s.io/etcd:3.5.15-0
I1001 07:26:56.820586    2830 image.go:178] daemon lookup for registry.k8s.io/coredns/coredns:v1.11.1: Error response from daemon: No such image: registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:27:06.804723    2830 cache_images.go:116] "registry.k8s.io/kube-scheduler:v1.31.0" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.804748    2830 cache_images.go:116] "registry.k8s.io/etcd:3.5.15-0" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.804757    2830 docker.go:337] Removing image: registry.k8s.io/kube-scheduler:v1.31.0
I1001 07:27:06.804765    2830 docker.go:337] Removing image: registry.k8s.io/etcd:3.5.15-0
I1001 07:27:06.804810    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/kube-scheduler:v1.31.0
I1001 07:27:06.804810    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/etcd:3.5.15-0
I1001 07:27:06.804853    2830 cache_images.go:116] "registry.k8s.io/pause:3.10" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.804861    2830 docker.go:337] Removing image: registry.k8s.io/pause:3.10
I1001 07:27:06.804877    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/pause:3.10
I1001 07:27:06.804904    2830 cache_images.go:116] "registry.k8s.io/coredns/coredns:v1.11.1" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.804913    2830 docker.go:337] Removing image: registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:27:06.804930    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:27:06.804996    2830 cache_images.go:116] "registry.k8s.io/kube-apiserver:v1.31.0" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.805005    2830 docker.go:337] Removing image: registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:27:06.805015    2830 cache_images.go:116] "registry.k8s.io/kube-controller-manager:v1.31.0" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.805021    2830 docker.go:337] Removing image: registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:27:06.805026    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:27:06.805042    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:27:06.804723    2830 cache_images.go:116] "gcr.io/k8s-minikube/storage-provisioner:v5" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.805055    2830 docker.go:337] Removing image: gcr.io/k8s-minikube/storage-provisioner:v5
I1001 07:27:06.805065    2830 ssh_runner.go:195] Run: docker rmi gcr.io/k8s-minikube/storage-provisioner:v5
I1001 07:27:06.805086    2830 cache_images.go:116] "registry.k8s.io/kube-proxy:v1.31.0" needs transfer: needs transfer timed out in 10.000000 seconds
I1001 07:27:06.805090    2830 docker.go:337] Removing image: registry.k8s.io/kube-proxy:v1.31.0
I1001 07:27:06.805113    2830 ssh_runner.go:195] Run: docker rmi registry.k8s.io/kube-proxy:v1.31.0
I1001 07:27:06.859001    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-scheduler_v1.31.0
I1001 07:27:06.908241    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-controller-manager_v1.31.0
I1001 07:27:06.908319    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-proxy_v1.31.0
I1001 07:27:06.908382    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/gcr.io/k8s-minikube/storage-provisioner_v5
I1001 07:27:06.908422    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-apiserver_v1.31.0
I1001 07:27:06.908446    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/coredns/coredns_v1.11.1
I1001 07:27:06.909941    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/etcd_3.5.15-0
I1001 07:27:06.909989    2830 cache_images.go:289] Loading image from: /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/pause_3.10
I1001 07:27:06.910068    2830 cache_images.go:92] duration metric: took 10.106642972s to LoadCachedImages
W1001 07:27:06.910310    2830 out.go:270] âŒ  Unable to load cached images: LoadCachedImages: stat /home/vboxuser/.minikube/cache/images/amd64/registry.k8s.io/kube-scheduler_v1.31.0: no such file or directory
I1001 07:27:06.911283    2830 kubeadm.go:934] updating node { 192.168.49.2 8443 v1.31.0 docker true true} ...
I1001 07:27:06.911372    2830 kubeadm.go:946] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.31.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I1001 07:27:06.911610    2830 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I1001 07:27:07.123160    2830 cni.go:84] Creating CNI manager for ""
I1001 07:27:07.123175    2830 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1001 07:27:07.123187    2830 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I1001 07:27:07.123202    2830 kubeadm.go:181] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.31.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I1001 07:27:07.123348    2830 kubeadm.go:187] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.31.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I1001 07:27:07.123392    2830 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.31.0
I1001 07:27:07.134560    2830 binaries.go:47] Didn't find k8s binaries: sudo ls /var/lib/minikube/binaries/v1.31.0: Process exited with status 2
stdout:

stderr:
ls: cannot access '/var/lib/minikube/binaries/v1.31.0': No such file or directory

Initiating transfer...
I1001 07:27:07.134603    2830 ssh_runner.go:195] Run: sudo mkdir -p /var/lib/minikube/binaries/v1.31.0
I1001 07:27:07.144566    2830 download.go:107] Downloading: https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubelet?checksum=file:https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubelet.sha256 -> /home/vboxuser/.minikube/cache/linux/amd64/v1.31.0/kubelet
I1001 07:27:07.144704    2830 download.go:107] Downloading: https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl?checksum=file:https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl.sha256 -> /home/vboxuser/.minikube/cache/linux/amd64/v1.31.0/kubectl
I1001 07:27:07.144960    2830 download.go:107] Downloading: https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubeadm?checksum=file:https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubeadm.sha256 -> /home/vboxuser/.minikube/cache/linux/amd64/v1.31.0/kubeadm
I1001 07:27:08.621566    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} gcr.io/k8s-minikube/storage-provisioner:v5
W1001 07:27:13.959016    2830 out.go:270] â—  Failing to connect to https://registry.k8s.io/ from both inside the minikube container and host machine
W1001 07:27:13.959086    2830 out.go:270] ðŸ’¡  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
I1001 07:27:25.982018    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/etcd:3.5.15-0
I1001 07:27:26.321130    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/coredns/coredns:v1.11.1
I1001 07:27:26.605938    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/kube-proxy:v1.31.0
I1001 07:27:26.891404    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/pause:3.10
I1001 07:27:27.260533    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/kube-controller-manager:v1.31.0
I1001 07:27:27.270391    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/kube-apiserver:v1.31.0
I1001 07:27:27.438932    2830 ssh_runner.go:195] Run: docker image inspect --format {{.Id}} registry.k8s.io/kube-scheduler:v1.31.0
I1001 07:28:11.874713    2830 out.go:201] 
W1001 07:28:11.879319    2830 out.go:270] âŒ  Exiting due to K8S_INSTALL_FAILED: Failed to update cluster: update primary control-plane node: downloading binaries: downloading kubelet: download failed: https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubelet?checksum=file:https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubelet.sha256: getter: &{Ctx:context.Background Src:https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubelet?checksum=file:https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubelet.sha256 Dst:/home/vboxuser/.minikube/cache/linux/amd64/v1.31.0/kubelet.download Pwd: Mode:2 Umask:---------- Detectors:[0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820 0x4eb7820] Decompressors:map[bz2:0xc0000e2d60 gz:0xc0000e2d68 tar:0xc0000e2cf0 tar.bz2:0xc0000e2d10 tar.gz:0xc0000e2d20 tar.xz:0xc0000e2d40 tar.zst:0xc0000e2d50 tbz2:0xc0000e2d10 tgz:0xc0000e2d20 txz:0xc0000e2d40 tzst:0xc0000e2d50 xz:0xc0000e2d70 zip:0xc0000e2d80 zst:0xc0000e2d78] Getters:map[file:0xc0021f1050 http:0xc000637090 https:0xc0006370e0] Dir:false ProgressListener:0x4e44750 Insecure:false DisableSymlinks:false Options:[0x12e5e60]}: read tcp 10.0.2.15:33156->151.101.65.55:443: read: connection reset by peer
W1001 07:28:11.882073    2830 out.go:270] 
W1001 07:28:11.885076    2830 out.go:293] [31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®[0m
[31mâ”‚[0m                                                                                           [31mâ”‚[0m
[31mâ”‚[0m    ðŸ˜¿  If the above advice does not help, please let us know:                             [31mâ”‚[0m
[31mâ”‚[0m    ðŸ‘‰  https://github.com/kubernetes/minikube/issues/new/choose                           [31mâ”‚[0m
[31mâ”‚[0m                                                                                           [31mâ”‚[0m
[31mâ”‚[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31mâ”‚[0m
[31mâ”‚[0m                                                                                           [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m
I1001 07:28:11.888037    2830 out.go:201] 


==> Docker <==
Oct 01 05:26:36 minikube systemd[1]: Stopping Docker Application Container Engine...
Oct 01 05:26:36 minikube dockerd[190]: time="2024-10-01T05:26:36.882997682Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Oct 01 05:26:36 minikube dockerd[190]: time="2024-10-01T05:26:36.883215222Z" level=info msg="Daemon shutdown complete"
Oct 01 05:26:36 minikube systemd[1]: docker.service: Deactivated successfully.
Oct 01 05:26:36 minikube systemd[1]: Stopped Docker Application Container Engine.
Oct 01 05:26:36 minikube systemd[1]: Starting Docker Application Container Engine...
Oct 01 05:26:36 minikube dockerd[608]: time="2024-10-01T05:26:36.928926432Z" level=info msg="Starting up"
Oct 01 05:26:36 minikube dockerd[608]: time="2024-10-01T05:26:36.953233583Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Oct 01 05:26:36 minikube dockerd[608]: time="2024-10-01T05:26:36.953497246Z" level=info msg="Loading containers: start."
Oct 01 05:26:37 minikube dockerd[608]: time="2024-10-01T05:26:37.262575052Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Oct 01 05:26:37 minikube dockerd[608]: time="2024-10-01T05:26:37.346178620Z" level=info msg="Loading containers: done."
Oct 01 05:26:37 minikube dockerd[608]: time="2024-10-01T05:26:37.363437326Z" level=info msg="Docker daemon" commit=3ab5c7d containerd-snapshotter=false storage-driver=overlay2 version=27.2.0
Oct 01 05:26:37 minikube dockerd[608]: time="2024-10-01T05:26:37.363580109Z" level=info msg="Daemon has completed initialization"
Oct 01 05:26:37 minikube dockerd[608]: time="2024-10-01T05:26:37.393596366Z" level=info msg="API listen on /var/run/docker.sock"
Oct 01 05:26:37 minikube dockerd[608]: time="2024-10-01T05:26:37.393737532Z" level=info msg="API listen on [::]:2376"
Oct 01 05:26:37 minikube systemd[1]: Started Docker Application Container Engine.
Oct 01 05:26:54 minikube dockerd[608]: time="2024-10-01T05:26:54.307321760Z" level=info msg="Processing signal 'terminated'"
Oct 01 05:26:54 minikube dockerd[608]: time="2024-10-01T05:26:54.308544534Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Oct 01 05:26:54 minikube systemd[1]: Stopping Docker Application Container Engine...
Oct 01 05:26:54 minikube dockerd[608]: time="2024-10-01T05:26:54.309852894Z" level=info msg="Daemon shutdown complete"
Oct 01 05:26:54 minikube systemd[1]: docker.service: Deactivated successfully.
Oct 01 05:26:54 minikube systemd[1]: Stopped Docker Application Container Engine.
Oct 01 05:26:54 minikube systemd[1]: Starting Docker Application Container Engine...
Oct 01 05:26:54 minikube dockerd[901]: time="2024-10-01T05:26:54.502946439Z" level=info msg="Starting up"
Oct 01 05:26:54 minikube dockerd[901]: time="2024-10-01T05:26:54.601035317Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Oct 01 05:26:54 minikube dockerd[901]: time="2024-10-01T05:26:54.601224588Z" level=info msg="Loading containers: start."
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.016151460Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.090501923Z" level=info msg="Processing signal 'terminated'"
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.104072589Z" level=info msg="Loading containers: done."
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.117813995Z" level=info msg="Docker daemon" commit=3ab5c7d containerd-snapshotter=false storage-driver=overlay2 version=27.2.0
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.117871962Z" level=info msg="Daemon has completed initialization"
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.150930149Z" level=info msg="API listen on /var/run/docker.sock"
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.151117936Z" level=info msg="API listen on [::]:2376"
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.152160913Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Oct 01 05:26:55 minikube dockerd[901]: time="2024-10-01T05:26:55.152277071Z" level=info msg="Daemon shutdown complete"
Oct 01 05:26:55 minikube systemd[1]: docker.service: Deactivated successfully.
Oct 01 05:26:55 minikube systemd[1]: Stopped Docker Application Container Engine.
Oct 01 05:26:55 minikube systemd[1]: Starting Docker Application Container Engine...
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.195460763Z" level=info msg="Starting up"
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.216859899Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.221734353Z" level=info msg="Loading containers: start."
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.488996061Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.566366560Z" level=info msg="Loading containers: done."
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.576655939Z" level=info msg="Docker daemon" commit=3ab5c7d containerd-snapshotter=false storage-driver=overlay2 version=27.2.0
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.576868072Z" level=info msg="Daemon has completed initialization"
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.613197873Z" level=info msg="API listen on /var/run/docker.sock"
Oct 01 05:26:55 minikube dockerd[1153]: time="2024-10-01T05:26:55.613508197Z" level=info msg="API listen on [::]:2376"
Oct 01 05:26:55 minikube systemd[1]: Started Docker Application Container Engine.
Oct 01 05:26:56 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Start docker client with request timeout 0s"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Hairpin mode is set to hairpin-veth"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Loaded network plugin cni"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Docker cri networking managed by network plugin cni"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Setting cgroupDriver systemd"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Oct 01 05:26:56 minikube cri-dockerd[1410]: time="2024-10-01T05:26:56Z" level=info msg="Start cri-dockerd grpc backend"
Oct 01 05:26:56 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID              POD


==> describe nodes <==
command /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" failed with error: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper
sudo: a password is required


==> dmesg <==
[Oct 1 05:10] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!
[  +0.191766] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended configuration space under this bridge
[  +0.372676] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +0.001236] platform eisa.0: EISA: Cannot allocate resource for mainboard
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 1
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 2
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 3
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 4
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 5
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 6
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 7
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 8
[  +1.748266] block sda: the capability attribute has been deprecated.
[  +0.314421] mtd device must be supplied (device name is empty)
[  +0.001246] systemd-journald[205]: File /var/log/journal/7ff0007f55424aee8f265e8ec5e94195/system.journal corrupted or uncleanly shut down, renaming and replacing.
[  +0.069142] vmwgfx 0000:00:02.0: [drm] *ERROR* vmwgfx seems to be running on an unsupported hypervisor.
[  +0.000001] vmwgfx 0000:00:02.0: [drm] *ERROR* This configuration is likely broken.
[  +0.000001] vmwgfx 0000:00:02.0: [drm] *ERROR* Please switch to a supported graphics device to avoid problems.
[  +2.579020] kauditd_printk_skb: 32 callbacks suppressed


==> kernel <==
 05:29:10 up 18 min,  0 users,  load average: 0.39, 0.77, 0.60
Linux minikube 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.4 LTS"


==> kubelet <==
-- No entries --

